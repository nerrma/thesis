---
header-includes: |
	\usepackage{amsmath}
	 \usepackage{fancyhdr}
	 \usepackage{physics}
	 \usepackage{hyperref}
	 \usepackage{graphicx}
	\graphicspath{ {./images/} }
	\DeclareMathOperator*{\argmax}{arg\,max}
	\DeclareMathOperator*{\argmin}{arg\,min}
title: "Iterative Approximate Cross Validation in High Dimensions"
author: "Sina Alsharif"
theme: "Frankfurt"
institute: "School of Computer Science and Engineering, University of New South Wales"
topic: "Thesis A"
date: "Thesis A (Term 2, 2023)"
colortheme: "orchid"
fonttheme: "professionalfonts"
toc: true
---

# Background
To set out the notation used throughout this seminar, we can define the Empirical Risk Minimisation (ERM) framework to solve a supervised learning problem. 

\pause

### General Problem Setting
- Input space $\mathcal{X}$ and an output space $\mathcal{Y}$.
- Generated by a *true* distribution $P(\mathcal{X}, \mathcal{Y})$.
- Aim is to find a mapping $h : \mathcal{X} \to \mathcal{Y}$ (called a hypothesis).
- Denote all possible combinations of input and output space as $\mathcal{D} = \{(X, Y) \in (\mathcal{X}, \mathcal{Y})\}$ (called a hypothesis).

## Risk

To measure the error (or loss) we make on a data point, define a function $\ell(h; D_i)$,
\begin{align*}
	\ell(h; D) = \sum_{i=1}^n \ell(h; D_i)
\end{align*}
as the loss for the dataset. Examples of $\ell$ are 0-1 loss (for classification) and a squared error (for regression).

\pause

### Risk
Define the **risk** of a hypothesis for the complete space of inputs and outputs as,
\begin{align*}
	R(h) = \mathbb{E}_{\mathcal{X}, \mathcal{Y}} [\ell(h; \mathcal{D})]
\end{align*}
The optimal hypothesis for the data is,
\begin{align*}
	h_{\mathcal{H}} = \argmin_{h \in \mathcal{H}} R(h)
\end{align*}


## Empirical Risk

As we cannot measure **true** risk, we seek an approximation using the observed data $D$.

### Empirical Risk
We define **empirical risk** of a hypothesis given data $D$ as,
\begin{align*}
	R_{\text{emp}}(h; D) = \frac{1}{n} \sum_{i=1}^n \ell(h; D_i)
\end{align*}
The optimal hypothesis *given observed data* $D$ is,
\begin{align*}
	h_D = \argmin_{h \in \mathcal{H}} R_{\text{emp}}(h; D)
\end{align*}
where $\mathcal{H}$ is a hypothesis space which a *learning algorithm* picks a hypothesis from.

### Issues with ERM

By the (weak) law of large numbers $R_{\text{emp}}(h; D) \to R(h; D)$ as $n \to \infty$, so it is reasonable to assume that $h_D$ converges to a minimiser of true risk.

# Literature Review
# Preliminary Work
# Future Plans
